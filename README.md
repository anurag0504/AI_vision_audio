# Multimodal AI Interactive Assistant

A Python-based interactive assistant that combines **computer vision**, **speech recognition**, and **natural language processing** to create a multimodal experience. The system detects gestures, analyzes facial and speech emotions, and provides dynamic responses via a user-friendly GUI.

## Features
- **Gesture Recognition:** Detects hand gestures like "thumbs up" or "wave" using Mediapipe.
- **Emotion Detection:**
  - Facial emotions (happy, sad, neutral) using facial landmarks.
  - Speech emotions (angry, calm) using audio signal analysis.
- **Multilingual Support:** Translates responses into different languages using Google Translate API.
- **Dynamic GUI:** Displays real-time video, detected gestures, emotions, and AI-generated responses.



